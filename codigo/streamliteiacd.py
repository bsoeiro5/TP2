import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from sklearn.decomposition import PCA
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import pickle
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC

st.set_page_config(layout="wide")

st.title("Student Performance Dashboard")

# Carregar dados
df = pd.read_csv('student-data.csv')  
df['passed'] = df['passed'].map({'yes': 1, 'no': 0})

# Criar vers√£o num√©rica do dataframe para an√°lise
ndf = pd.read_csv('student-data.csv')
ndf['passed'] = ndf['passed'].map({'yes': 1, 'no': 0})
ndf['school'] = ndf['school'].map({'GP': 1, 'MS': 0})
ndf['sex'] = ndf['sex'].map({'F': 1, 'M': 0})
ndf['address'] = ndf['address'].map({'R': 1, 'U': 0})
ndf['famsize'] = ndf['famsize'].map({'GT3': 1, 'LE3': 0})
ndf['Pstatus'] = ndf['Pstatus'].map({'T': 1, 'A': 0})
ndf['schoolsup'] = ndf['schoolsup'].map({'yes': 1, 'no': 0})
ndf['famsup'] = ndf['famsup'].map({'yes': 1, 'no': 0})
ndf['paid'] = ndf['paid'].map({'yes': 1, 'no': 0})
ndf['activities'] = ndf['activities'].map({'yes': 1, 'no': 0})
ndf['nursery'] = ndf['nursery'].map({'yes': 1, 'no': 0})
ndf['higher'] = ndf['higher'].map({'yes': 1, 'no': 0})
ndf['internet'] = ndf['internet'].map({'yes': 1, 'no': 0})
ndf['romantic'] = ndf['romantic'].map({'yes': 1, 'no': 0})
ndf = pd.get_dummies(ndf, columns=['Mjob', 'Fjob'], drop_first=True)
ndf = pd.get_dummies(ndf, columns=['reason'], drop_first=True)
ndf = pd.get_dummies(ndf, columns=['guardian'], drop_first=True)
ndf = ndf.replace({True: 1, False: 0})

# Treinar modelos
X = ndf.drop(['passed'], axis=1)
y = ndf['passed']

# Definir modelos
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'KNN': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'MLP Classifier': MLPClassifier(random_state=42, max_iter=500, early_stopping=True)
}

# Treinar todos os modelos
for name, model in models.items():
    model.fit(X, y)

# Navega√ß√£o
tabs = st.tabs(["Dashboard", "Novo Aluno"])

with tabs[0]:
    with st.expander("Trabalho realizado por:"):
        st.markdown("[√Älvaro Castro (FCUP_IACD:202403514)](https://www.linkedin.com/in/%C3%A1lvaro-vieira-de-castro-1571b4332/)")
        st.write("[Bernardo Soeiro (FCUP_IACD:202403514)](https://www.linkedin.com/in/bernardo-soeiro-46347831a/)")
        st.write("[Francisco Machado (FCUP_IACD:202403514)](https://www.linkedin.com/in/franciscovilasboasmachado/)")

    st.markdown("---")

    st.title("0. Introdu√ß√£o")

    st.markdown("""
    <div style='text-align: justify'>
    O insucesso escolar continua a ser uma das principais preocupa√ß√µes no contexto educativo atual, com impactos significativos na trajet√≥ria acad√©mica e pessoal dos alunos. A dete√ß√£o precoce de estudantes em risco de reprova√ß√£o √© essencial para permitir interven√ß√µes pedag√≥gicas eficazes.

    Neste projeto, propomos o desenvolvimento de um <strong>Student Intervention System</strong>, baseado em t√©cnicas de <em>Supervised Machine Learning</em>, com o objetivo de prever se um aluno ir√° ou n√£o ser aprovado no exame final, utilizando dados reais recolhidos de duas escolas de ensino secund√°rio em Portugal.

    Para atingir esse objetivo, baseamo-nos em v√°rias etapas fundamentais da ci√™ncia de dados, nomeadamente: <strong>an√°lise explorat√≥ria dos dados</strong>, <strong>tratamento e transforma√ß√£o das vari√°veis</strong>, <strong>treino de modelos de classifica√ß√£o</strong> e <strong>avalia√ß√£o rigorosa dos seus desempenhos</strong>. Cada etapa √© essencial para garantir que o sistema resultante seja n√£o s√≥ eficaz, mas tamb√©m transparente e replic√°vel.
    </div>

    ### M√©todos de Aprendizagem Supervisionada

    -  K-Nearest Neighbors (KNN)  
    -  Decision Tree  
    -  Random Forest  
    -  Logistic Regression  
    -  Gradient Boosting  
    -  Support Vector Machine (SVM)  
    -  Rede Neural (Neural Network)
    """, unsafe_allow_html=True)

    st.subheader("0.1. Sobre o estudo")
    st.markdown("""
    <div style='text-align: justify'>
    Tipicamente, como em muitos projetos de <strong>Data Science</strong>, todo o c√≥digo implementado foi desenvolvido em <strong>Jupyter Notebook</strong>.

    <br>

    Alguns trechos de c√≥digo ser-lhe-√£o apresentados ao longo desta documenta√ß√£o. Para al√©m do foco prim√°rio do projeto, desej√°vamos que qualquer dataset pudesse ser convertido num <strong>DataFrame</strong> e que, posteriormente, pudesse ser <strong>processado e polido</strong> segundo os m√©todos que desenhamos, a fim de alimentar um <strong>algoritmo de machine learning</strong>.
    </div>
    """, unsafe_allow_html=True)

    st.markdown("---")

    st.title("1. An√°lise Explorat√≥ria dos Dados")
    st.markdown("""
    <div style='text-align: justify'>
    Talvez o processo mais importante de todo o estudo. Um dos grandes desafios que qualquer <strong>Data Scientist</strong> enfrenta √© a forma crua como os dados lhe s√£o apresentados. Analogamente, podemos pensar que o dataset inicial √© como um min√©rio de ouro rec√©m-extra√≠do: cont√©m impurezas, fragmentos de outras rochas, e precisa ser cuidadosamente limpo e polido. O nosso trabalho, √† semelhan√ßa do mineiro, √© extrair valor ‚Äî neste caso, <strong>informa√ß√£o relevante</strong> para alimentar algoritmos de <em>machine learning</em>.

    <br>

    Neste projeto, utiliz√°mos o ficheiro <code>student-data.csv</code>, que cont√©m dados reais recolhidos de duas escolas secund√°rias em Portugal. Cada linha do <code>DataFrame</code> representa um estudante individual, e cada coluna representa uma caracter√≠stica (atributo) relevante para o seu desempenho escolar ‚Äî como estatuto familiar, h√°bitos de estudo, consumo de √°lcool, tempo de desloca√ß√£o, apoio extra-curricular, entre outros.

    <br>

    Contam-se <strong>395 estudantes</strong> descritos por <strong>33 atributos</strong>, que combinam vari√°veis <strong>categ√≥ricas</strong> (como g√©nero, tipo de escola, curso frequentado) e <strong>num√©ricas</strong> (como notas anteriores, n√∫mero de faltas, idade). Este tipo de informa√ß√£o serve de base para a an√°lise explorat√≥ria, a identifica√ß√£o de padr√µes e a cria√ß√£o de modelos preditivos.

    <br>

    Uma boa an√°lise dos dados √© determinante para a qualidade dos resultados. Foi-nos incumbido n√£o s√≥ de compreender como os dados est√£o representados, mas tamb√©m de <strong>relacionar vari√°veis</strong>, <strong>tratar valores em falta</strong>, e <strong>transformar os atributos</strong> para que estejam prontos a ser utilizados nos algoritmos de aprendizagem supervisionada.
    </div>
    """, unsafe_allow_html=True)
    st.dataframe(df)

    st.subheader("Guia de An√°lise Explorat√≥ria de Dados")

    st.markdown("""
    <div style='text-align: justify'>
    Assim, de modo a ultrapassarmos esta fase corretamente, decidimos que a nossa <strong>an√°lise explorat√≥ria de dados</strong> (<em>data analysis</em>) se guiaria pelos seguintes aspetos principais:
    </div>

    <ul>
        <li>üìä <strong>Estat√≠sticas descritivas b√°sicas</strong> ‚Äì para compreender a distribui√ß√£o geral dos dados.</li>
        <li>üîç <strong>An√°lise de vari√°veis</strong> ‚Äì para examinar a import√¢ncia, variabilidade e rela√ß√£o entre os atributos.</li>
        <li>üö® <strong>Dete√ß√£o de outliers</strong> ‚Äì para identificar valores at√≠picos que possam afetar os modelos preditivos.</li>
    </ul>
    """, unsafe_allow_html=True)
    st.markdown("---")

    st.subheader("1.1. Novo Dataset")

    st.markdown("""
    Para que os algoritmos de Machine Learning consigam interpretar corretamente os dados, √© necess√°rio que todas as vari√°veis estejam em formato num√©rico. 
    Muitos modelos n√£o conseguem lidar diretamente com vari√°veis categ√≥ricas (por exemplo, `sexo`, `escola`, `endere√ßo`), pelo que transform√°mos essas vari√°veis 
    em valores bin√°rios (0 ou 1), ou aplic√°mos codifica√ß√£o one-hot em casos com m√∫ltiplas categorias.

    Este processo garante a compatibilidade com modelos supervisionados e melhora a performance geral da aprendizagem autom√°tica.
    """)

    # Exibir uma amostra do novo dataset
    st.markdown("### üîé Pr√©-visualiza√ß√£o do novo dataset transformado:")
    st.dataframe(df.head(), use_container_width=True)
    codigo_transformacao = '''
    df = pd.read_csv('student-data.csv')  
    df['passed'] = df['passed'].map({'yes': 1, 'no': 0})
    df['school'] = df['school'].map({'GP': 1, 'MS': 0})
    df['sex'] = df['sex'].map({'F': 1, 'M': 0})
    df['address'] = df['address'].map({'R': 1, 'U': 0})
    df['famsize'] = df['famsize'].map({'GT3': 1, 'LE3': 0})
    df['Pstatus'] = df['Pstatus'].map({'T': 1, 'A': 0})
    df['schoolsup'] = df['schoolsup'].map({'yes': 1, 'no': 0})
    df['famsup'] = df['famsup'].map({'yes': 1, 'no': 0})
    df['paid'] = df['paid'].map({'yes': 1, 'no': 0})
    df['activities'] = df['activities'].map({'yes': 1, 'no': 0})
    df['nursery'] = df['nursery'].map({'yes': 1, 'no': 0})
    df['higher'] = df['higher'].map({'yes': 1, 'no': 0})
    df['internet'] = df['internet'].map({'yes': 1, 'no': 0})
    df['romantic'] = df['romantic'].map({'yes': 1, 'no': 0})
    df = pd.get_dummies(df, columns=['Mjob', 'Fjob'], drop_first=True)
    df = pd.get_dummies(df, columns=['reason'], drop_first=True)
    df = pd.get_dummies(df, columns=['guardian'], drop_first=True)
    df = df.replace({True: 1, False: 0})
    df
    '''
    st.markdown("### üíª C√≥digo utilizado para transformar o dataset:")
    st.code(codigo_transformacao, language='python')

    st.markdown("---")
    st.subheader("1.2. Matriz de Correla√ß√£o")

    # Calcular matriz de correla√ß√£o
    corr_matrix = ndf.corr()

    # Mostrar heatmap com Plotly
    fig = px.imshow(
        corr_matrix,
        text_auto=True,
        aspect="auto",
        color_continuous_scale='Viridis',
        title='Matriz de Correla√ß√£o Interativa (Vari√°veis Num√©ricas + Alvo)'
    )
    st.plotly_chart(fig)
    st.markdown("---")
    st.subheader("1.3. Estat√≠sticas Descritivas B√°sicas")

    st.markdown("""
    <div style='text-align: justify'>
    Um dos sistemas mais simples, mas ainda assim dos mais eficazes, √© a realiza√ß√£o de uma <strong>an√°lise descritiva</strong> de cada atributo. 
    Entende-se por estat√≠sticas descritivas b√°sicas as seguintes medidas, que s√£o aplic√°veis apenas a <em>features num√©ricas</em>:
    </div>

    <ul>
        <li>üìå <strong>M√©dia</strong></li>
        <li>üìå <strong>Mediana</strong></li>
        <li>üìå <strong>Desvio Padr√£o</strong></li>
        <li>üìå <strong>Assimetria</strong></li>
        <li>üìå <strong>Curtose</strong></li>
    </ul>

    <p>Abaixo encontram-se tabelas que apresentam essas estat√≠sticas para cada atributo, juntamente com uma breve descri√ß√£o da sua import√¢ncia.</p>
    """, unsafe_allow_html=True)

    # Selecionar apenas colunas num√©ricas
    numeric_df = ndf.select_dtypes(include=['number'])

    # Calcular estat√≠sticas
    mean = numeric_df.mean().rename("M√©dia")
    median = numeric_df.median().rename("Mediana")
    std_dev = numeric_df.std().rename("Desvio Padr√£o")
    skewness = numeric_df.skew().rename("Assimetria")
    kurtosis = numeric_df.kurt().rename("Curtose")

    # Concatenar tudo numa √∫nica tabela
    statistics_df = pd.concat([mean, median, std_dev, skewness, kurtosis], axis=1)

    # Mostrar tabela no Streamlit
    st.dataframe(statistics_df.style.format(precision=2), use_container_width=True)

    st.markdown("""
    - **üìä M√©dia:** Representa o valor central dos valores de cada atributo, sendo muito √∫til para resumir grandes quantidades de dados num √∫nico valor.
    - **üìà Mediana:** √ötil para entender a tend√™ncia central dos dados, especialmente quando h√° valores extremos (outliers), pois n√£o √© afetada por eles como a m√©dia.
    - **üìâ Desvio Padr√£o:** Indica o grau de dispers√£o dos dados. Um valor alto significa que os dados est√£o espalhados numa ampla gama; um valor baixo indica que est√£o mais concentrados em torno da m√©dia.
    - **üìê Assimetria:** Ajuda a entender a simetria da distribui√ß√£o. Assimetrias podem indicar presen√ßa de outliers ou sugerir a necessidade de transformar os dados.
    - **‚õ∞Ô∏è Curtose:** Informa sobre a forma da distribui√ß√£o ‚Äî se √© mais "pontiaguda" ou achatada ‚Äî o que pode ser relevante em an√°lises estat√≠sticas e modelagem.
    """)

    st.markdown("---")
    st.subheader("1.4. Ajuste dos Outliers")

    st.markdown("""
    Outliers s√£o valores que se desviam significativamente da maioria dos dados em um conjunto. Eles podem surgir por erros de medi√ß√£o, entrada de dados incorreta ou at√© por varia√ß√µes naturais. Sua presen√ßa pode influenciar negativamente a performance de alguns modelos de Machine Learning, distorcendo m√©tricas e padr√µes.

    A seguir, aplicamos duas abordagens para identificar poss√≠veis outliers:
    """)

    # --- Subt√≠tulo 1.4.1 ---
    st.subheader("1.4.1. Identifica√ß√£o Visual dos Outliers")

    st.markdown("""
    Nesta abordagem, utilizamos o intervalo interquartil (IQR) para detectar outliers. 
    A t√©cnica compara cada valor com os limites inferiores e superiores baseados nos quartis.

    - **Outliers**: valores fora do intervalo \[Q1 - 1.5√óIQR, Q3 + 1.5√óIQR\]
    - **Outliers severos**: valores fora do intervalo \[Q1 - 3√óIQR, Q3 + 3√óIQR\]
    """)

    # C√°lculo dos outliers com c√≥digo formatado
    codigo_outliers_visual = '''
    numeric_df = df.select_dtypes(include=['number'])
    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
    numeric_df = df[numeric_cols]

    Q1 = numeric_df.quantile(0.25)
    Q3 = numeric_df.quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = ((numeric_df < lower_bound) | (numeric_df > upper_bound))
    outliers_count = outliers.sum()
    print("N√∫mero de outliers por coluna:\\n", outliers_count)

    lower_bound_severe = Q1 - 3 * IQR
    upper_bound_severe = Q3 + 3 * IQR

    outliers_severe = ((numeric_df < lower_bound_severe) | (numeric_df > upper_bound_severe))
    outliers_severe_count = outliers_severe.sum()
    print("N√∫mero de outliers severos por coluna:\\n", outliers_severe_count)

    outliers_count.plot(kind='bar', figsize=(10, 6), title='N√∫mero de Outliers por Feature')
    plt.xlabel('Features')
    plt.ylabel('N√∫mero de Outliers Severos')
    plt.show()
    '''
    st.code(codigo_outliers_visual, language='python')

    # --- Subt√≠tulo 1.4.2 ---
    st.subheader("1.4.2. Identifica√ß√£o via PCA (Redu√ß√£o de Dimensionalidade)")

    st.markdown("""
    Outra abordagem foi a aplica√ß√£o de **PCA (An√°lise de Componentes Principais)** para reduzir os dados para duas dimens√µes.
    A dist√¢ncia de cada ponto √† origem foi usada para identificar valores extremos, ou seja, poss√≠veis outliers.

    Selecionamos os **2% mais distantes** como potenciais outliers.
    """)

    codigo_outliers_pca = '''
    from sklearn.decomposition import PCA
    pca_2d = PCA(n_components=2)

    X_train_processed = preprocessor.fit_transform(X_train)

    X_train_pca_2d = pca_2d.fit_transform(X_train_processed)

    distances_2d = np.sqrt(np.sum(X_train_pca_2d**2, axis=1))
    outlier_threshold_2d = np.percentile(distances_2d, 98)  
    outliers_pca_indices_train = X_train.index[distances_2d > outlier_threshold_2d]

    print(f'Threshold de dist√¢ncia (Percentil 98 no espa√ßo 2D - Treino): {outlier_threshold_2d:.2f}')
    print(f'N√∫mero de outliers potenciais identificados no treino: {len(outliers_pca_indices_train)}')
    if not outliers_pca_indices_train.empty:
        print(f'√çndices dos outliers potenciais no treino: {outliers_pca_indices_train.tolist()}')
    else:
        print('Nenhum outlier potencial identificado no treino.')

    fig = px.scatter(x=X_train_pca_2d[:, 0], y=X_train_pca_2d[:, 1], color=y_train.astype(str),
                    labels={'color': 'Passed'}, title='PCA (2 Componentes) com Outliers Potenciais - Treino',
                    hover_name=X_train.index)
    fig.add_trace(go.Scatter(x=X_train_pca_2d[distances_2d > outlier_threshold_2d, 0],
                            y=X_train_pca_2d[distances_2d > outlier_threshold_2d, 1],
                            mode='markers', marker=dict(color='red', size=10, symbol='x'),
                            name='Outlier Potencial', hoverinfo='text',
                            hovertext=[f'Index: {i}' for i in outliers_pca_indices_train]))
    fig.update_layout(xaxis_title='Componente Principal 1', yaxis_title='Componente Principal 2')
    fig.show()
    '''
    st.code(codigo_outliers_pca, language='python')

    # --- Decis√£o final ---
    st.subheader("üìå Decis√£o Final")

    st.markdown("""
    Ap√≥s identificar poss√≠veis outliers pelas duas abordagens apresentadas, decidimos **manter os outliers para a modelagem inicial**.

    Isso nos permite observar se esses valores realmente impactam negativamente os modelos. Se necess√°rio, na fase de otimiza√ß√£o e valida√ß√£o dos modelos, retornaremos ao tratamento destes valores.
    """)

    st.markdown("---")

    st.title("2. Algoritmos de Supervised Machine Learning")

    st.subheader("O que √© Aprendizagem Supervisionada?")

    st.markdown("""
    Os algoritmos de **Aprendizagem Supervisionada** s√£o t√©cnicas que utilizam dados previamente rotulados para treinar modelos capazes de realizar **previs√µes** ou **classifica√ß√µes**.

    Durante esse processo de treino, o modelo aprende a associar as **vari√°veis de entrada (features)** com os **resultados esperados (labels)**, ajustando seus par√¢metros internos para minimizar o erro entre as previs√µes geradas e os valores reais.
    """)


    st.subheader("üîç Algoritmos")

    st.markdown("""
    Nesta sec√ß√£o, treinamos e avaliamos o desempenho inicial de diferentes modelos de classifica√ß√£o usando **valida√ß√£o cruzada** no conjunto de treino pr√©-processado.

    **Modelos a explorar:**
    - Regress√£o Log√≠stica
    - K-Nearest Neighbors (KNN)
    - √Årvore de Decis√£o
    - Random Forest
    - Gradient Boosting
    - Support Vector Machine (SVM)
    - Rede Neuronal (MLP Classifier)
    """)

    st.markdown("---")
    st.subheader("2.1. Aplica√ß√£o dos Algoritmos")

    codigo = """
    models = {
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        'KNN': KNeighborsClassifier(),
        'Decision Tree': DecisionTreeClassifier(random_state=42),
        'Random Forest': RandomForestClassifier(random_state=42),
        'Gradient Boosting': GradientBoostingClassifier(random_state=42),
        'SVM': SVC(probability=True, random_state=42), 
        'MLP Classifier': MLPClassifier(random_state=42, max_iter=500, early_stopping=True) 
    }

    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    results_cv = {}

    print("--- Avalia√ß√£o Inicial com Valida√ß√£o Cruzada Estratificada (Treino) ---")

    scoring_metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']

    for name, model in models.items():
        print(f'A avaliar {name}...')
        metrics_scores = {metric: cross_val_score(model, X_train_processed, y_train, cv=skf, scoring=metric) for metric in scoring_metrics}
        results_cv[name] = {metric: scores.mean() for metric, scores in metrics_scores.items()}
        print(f'{name} - Acur√°cia M√©dia: {results_cv[name]["accuracy"]:.4f}')

    results_cv_df = pd.DataFrame(results_cv).T
    print('\\n--- Resultados M√©dios da Valida√ß√£o Cruzada (Treino) ---')
    display(results_cv_df.style.highlight_max(axis=0, color='lightgreen'))

    fig = px.bar(results_cv_df.reset_index().melt(id_vars='index', var_name='M√©trica', value_name='Score'),
                x='index', y='Score', color='M√©trica', barmode='group',
                title='Compara√ß√£o de M√©tricas dos Modelos (Valida√ß√£o Cruzada no Treino)',
                labels={'index': 'Modelo'})
    fig.show()
    """

    st.code(codigo, language='python')

    st.markdown("---")
    st.subheader("2.2. Otimiza√ß√£o e Avalia√ß√£o Avan√ßada")
    st.markdown("""
    Com base nos resultados iniciais, selecionamos alguns modelos promissores para otimiza√ß√£o de hiperpar√¢metros e avaliamos o impacto do tratamento do desbalanceamento de classes usando SMOTE.

    *   **Otimiza√ß√£o de Hiperpar√¢metros:** Usar GridSearchCV para encontrar os melhores par√¢metros.
    *   **Tratamento de Desbalanceamento (SMOTE):** Aplicar SMOTE no conjunto de treino para lidar com a ligeira predomin√¢ncia da classe 'yes'.
    *   **Avalia√ß√£o Final no Teste:** Avaliar os modelos otimizados (com e sem SMOTE) no conjunto de teste.
    """)
    
    st.markdown("---")
    st.title("3. Alunos com Necessidades Especiais")

    st.markdown("""
    <div style='text-align: justify'>
    A identifica√ß√£o precoce de alunos com necessidades educativas especiais representa um dos maiores desafios no contexto educacional contempor√¢neo. Tradicionalmente, esta identifica√ß√£o depende de avalia√ß√µes psicopedag√≥gicas individualizadas, que embora eficazes, s√£o processos demorados e que exigem recursos significativos. Neste projeto, exploramos uma abordagem complementar baseada em t√©cnicas de aprendizagem n√£o-supervisionada, especificamente a clusteriza√ß√£o K-Means, para identificar potenciais grupos de alunos que possam beneficiar de interven√ß√µes educativas personalizadas.
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("Metodologia de Identifica√ß√£o")
    
    st.markdown("""
    <div style='text-align: justify'>
    A nossa abordagem baseia-se na premissa de que alunos com necessidades educativas especiais frequentemente apresentam padr√µes distintos em m√∫ltiplas vari√°veis acad√©micas e comportamentais. Utilizando o algoritmo K-Means, conseguimos agrupar os alunos em clusters com caracter√≠sticas semelhantes, permitindo a identifica√ß√£o de grupos que possam necessitar de maior aten√ß√£o pedag√≥gica.
    
    O processo de identifica√ß√£o segue v√°rias etapas fundamentais. Primeiramente, selecionamos as vari√°veis mais relevantes para a an√°lise, focando em indicadores acad√©micos e comportamentais que possam sinalizar necessidades especiais. Em seguida, aplicamos normaliza√ß√£o aos dados para garantir que todas as vari√°veis contribuam equitativamente para a an√°lise, independentemente das suas escalas originais.
    
    Ap√≥s a prepara√ß√£o dos dados, aplicamos o algoritmo K-Means para agrupar os alunos em tr√™s clusters distintos. Esta escolha de tr√™s clusters permite-nos identificar grupos com caracter√≠sticas de alto, m√©dio e baixo desempenho, facilitando a identifica√ß√£o de padr√µes espec√≠ficos. Uma vez formados os clusters, analisamos detalhadamente as caracter√≠sticas de cada grupo, com especial aten√ß√£o √†s taxas de aprova√ß√£o.
    
    O cluster com a menor taxa de aprova√ß√£o √© identificado como potencial grupo de alunos com necessidades educativas especiais. Este grupo tipicamente apresenta um conjunto de caracter√≠sticas distintivas que podem incluir maior dificuldade de aprendizagem, menor suporte familiar ou escolar, ou outros fatores que contribuem para o baixo desempenho acad√©mico.
    </div>
    """, unsafe_allow_html=True)

    codigo = """
        X_special = X_train_special[available_vars].copy()
    scaler = StandardScaler()
    X_special_scaled = scaler.fit_transform(X_special)

    # Aplicar K-Means
    kmeans = KMeans(n_clusters=3, random_state=42)
    X_train_special['cluster'] = kmeans.fit_predict(X_special_scaled)

    # Adicionar passed_numeric se existir
    if 'passed_numeric' in X_train.columns:
        X_train_special['passed_numeric'] = X_train['passed_numeric']
        available_vars.append('passed_numeric')
    elif 'passed_numeric' in df.columns:  # Se estiver no DataFrame original
        X_train_special['passed_numeric'] = df.loc[X_train.index, 'passed_numeric']
        available_vars.append('passed_numeric')

    # Analisar caracter√≠sticas por cluster
    cluster_stats = X_train_special.groupby('cluster')[available_vars].mean()
    print("\nCaracter√≠sticas por cluster:")
    print(cluster_stats)

    # Identificar o cluster com menor taxa de aprova√ß√£o (se passed_numeric existir)
    if 'passed_numeric' in X_train_special.columns:
        approval_by_cluster = X_train_special.groupby('cluster')['passed_numeric'].mean() * 100
        worst_cluster = approval_by_cluster.idxmin()
        print(f"\nCluster {worst_cluster} tem a menor taxa de aprova√ß√£o: {approval_by_cluster[worst_cluster]:.2f}%")
        print("Este cluster pode representar alunos com necessidades especiais.")

        # Identificar alunos no cluster de risco
        special_needs_candidates = X_train_special[X_train_special['cluster'] == worst_cluster].index
        print(f"N√∫mero de alunos no cluster de risco: {len(special_needs_candidates)}")
        # Gr√°fico de barras para visualiza√ß√£o do n√∫mero de alunos por cluster
        cluster_counts = X_train_special['cluster'].value_counts().sort_index()
        """

    st.code(codigo, language='python')

    st.markdown("---")
    st.title("4. Conclus√µes sobre os Algoritmos Utilizados")
    
    st.markdown("""
    <div style='text-align: justify'>
    Ap√≥s a implementa√ß√£o, treino e avalia√ß√£o dos diversos algoritmos de aprendizagem supervisionada neste projeto, chegamos a conclus√µes importantes sobre o desempenho e aplicabilidade de cada um deles para o problema de previs√£o de aprova√ß√£o de estudantes.
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("4.1. An√°lise Comparativa dos Modelos")
    
    st.markdown("""
    <div style='text-align: justify'>
    A an√°lise comparativa dos modelos implementados revelou padr√µes interessantes quanto √† sua efic√°cia na previs√£o do sucesso acad√©mico dos estudantes:
    
    **Random Forest e Decision Tree** destacaram-se pela sua capacidade de capturar rela√ß√µes n√£o-lineares complexas nos dados educacionais. Estes modelos apresentaram um equil√≠brio not√°vel entre precis√£o e capacidade de generaliza√ß√£o, sendo particularmente eficazes na identifica√ß√£o de estudantes em risco de reprova√ß√£o.
    
    **KNN (K-Nearest Neighbors)** demonstrou um desempenho surpreendentemente bom, sugerindo que estudantes com perfis semelhantes tendem a ter resultados acad√©micos semelhantes. Este modelo √© especialmente √∫til quando existem "clusters" naturais de estudantes com caracter√≠sticas e desempenhos similares.
    
    **Regress√£o Log√≠stica**, apesar da sua simplicidade, mostrou-se menos eficaz para este problema espec√≠fico, indicando que as rela√ß√µes entre as vari√°veis preditoras e o sucesso acad√©mico n√£o s√£o puramente lineares. No entanto, a sua interpretabilidade continua a ser uma vantagem significativa em contextos educacionais onde a explicabilidade √© importante.
    
    **Gradient Boosting** apresentou resultados promissores ap√≥s otimiza√ß√£o, mas com tend√™ncia para overfitting quando n√£o adequadamente regularizado. Este modelo beneficiou significativamente da otimiza√ß√£o de hiperpar√¢metros.
    
    **SVM (Support Vector Machine)** mostrou um desempenho moderado, sendo mais eficaz ap√≥s a normaliza√ß√£o dos dados e otimiza√ß√£o de par√¢metros. A sua capacidade de lidar com fronteiras de decis√£o complexas foi valiosa para este problema.
    
    **MLP Classifier (Rede Neural)** demonstrou potencial para capturar padr√µes complexos nos dados, mas exigiu um ajuste cuidadoso para evitar overfitting, especialmente considerando o tamanho limitado do dataset.
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("4.2. Fatores Determinantes para o Sucesso Acad√©mico")
    
    st.markdown("""
    <div style='text-align: justify'>
    A an√°lise da import√¢ncia das features revelou os fatores mais determinantes para o sucesso acad√©mico dos estudantes:
    
    1. **Hist√≥rico de reprova√ß√µes anteriores** emergiu consistentemente como o preditor mais forte do desempenho futuro, indicando a import√¢ncia de interven√ß√µes precoces.
    
    2. **Tempo de estudo semanal** mostrou uma correla√ß√£o positiva significativa com a aprova√ß√£o, refor√ßando a import√¢ncia de h√°bitos de estudo regulares.
    
    3. **Educa√ß√£o dos pais** (especialmente da m√£e) demonstrou um impacto consider√°vel no desempenho acad√©mico, sublinhando a influ√™ncia do ambiente familiar.
    
    4. **Consumo de √°lcool** (especialmente aos fins-de-semana) correlacionou-se negativamente com o sucesso acad√©mico, destacando a import√¢ncia de abordar quest√µes comportamentais.
    
    5. **Assiduidade** (n√∫mero de faltas) tamb√©m se revelou um preditor importante, com maior absentismo associado a menor probabilidade de aprova√ß√£o.
    </div>
    """, unsafe_allow_html=True)
    
    st.subheader("4.3. Limita√ß√µes e Trabalho Futuro")
    
    st.markdown("""
    <div style='text-align: justify'>
    Apesar dos resultados promissores, identific√°mos algumas limita√ß√µes importantes:
    
    - O **tamanho limitado do dataset** (395 estudantes) pode afetar a generaliza√ß√£o para popula√ß√µes estudantis mais diversas
    - A **natureza est√°tica dos dados** n√£o captura a evolu√ß√£o do desempenho ao longo do tempo
    - Alguns **fatores potencialmente relevantes** (como sa√∫de mental, motiva√ß√£o intr√≠nseca, qualidade do ensino) n√£o est√£o representados no dataset
    
    Para trabalho futuro, recomendamos:
    
    - **Expandir o dataset** com dados de mais escolas e contextos educativos diversos
    - Implementar um **sistema de monitoriza√ß√£o cont√≠nua** que acompanhe a evolu√ß√£o do desempenho dos estudantes
    - Explorar t√©cnicas de **aprendizagem profunda** para capturar padr√µes temporais em dados educacionais longitudinais
    - Integrar **dados qualitativos** sobre experi√™ncias e perce√ß√µes dos estudantes
    - Desenvolver **interfaces mais interativas** para educadores, permitindo simula√ß√µes de interven√ß√µes e an√°lises de cen√°rios
    </div>
    """, unsafe_allow_html=True)

with tabs[1]:
    st.title("Previs√£o para Novo Aluno")
    
    st.markdown("""
    Nesta sec√ß√£o, voc√™ pode inserir os dados de um novo aluno para prever se ele ser√° aprovado ou n√£o no exame final.
    
    Preencha todos os campos abaixo com as informa√ß√µes do aluno e clique em "Prever" para obter o resultado.
    """)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("Dados Pessoais")
        school = st.selectbox("Escola", ["GP", "MS"], help="GP - Gabriel Pereira ou MS - Mousinho da Silveira")
        sex = st.selectbox("Sexo", ["F", "M"], help="F - Feminino ou M - Masculino")
        age = st.number_input("Idade", min_value=15, max_value=22, value=16, help="Idade do aluno")
        address = st.selectbox("Endere√ßo", ["U", "R"], help="U - Urbano ou R - Rural")
        famsize = st.selectbox("Tamanho da Fam√≠lia", ["LE3", "GT3"], help="LE3 - Menor ou igual a 3 ou GT3 - Maior que 3")
        Pstatus = st.selectbox("Status dos Pais", ["T", "A"], help="T - Vivendo juntos ou A - Separados")
        
    with col2:
        st.subheader("Educa√ß√£o e Fam√≠lia")
        Medu = st.selectbox("Educa√ß√£o da M√£e", [0, 1, 2, 3, 4], help="0 - nenhuma, 1 - prim√°rio, 2 - 5¬∫ a 9¬∫ ano, 3 - secund√°rio, 4 - superior")
        Fedu = st.selectbox("Educa√ß√£o do Pai", [0, 1, 2, 3, 4], help="0 - nenhuma, 1 - prim√°rio, 2 - 5¬∫ a 9¬∫ ano, 3 - secund√°rio, 4 - superior")
        Mjob = st.selectbox("Profiss√£o da M√£e", ["teacher", "health", "services", "at_home", "other"])
        Fjob = st.selectbox("Profiss√£o do Pai", ["teacher", "health", "services", "at_home", "other"])
        reason = st.selectbox("Raz√£o para escolher a escola", ["home", "reputation", "course", "other"])
        guardian = st.selectbox("Respons√°vel", ["mother", "father", "other"])
        
    with col3:
        st.subheader("Estudo e Tempo Livre")
        traveltime = st.selectbox("Tempo de viagem para a escola", [1, 2, 3, 4], help="1 - <15 min., 2 - 15-30 min., 3 - 30-60 min., 4 - >60 min.")
        studytime = st.selectbox("Tempo de estudo semanal", [1, 2, 3, 4], help="1 - <2 horas, 2 - 2-5 horas, 3 - 5-10 horas, 4 - >10 horas")
        failures = st.selectbox("N√∫mero de reprova√ß√µes anteriores", [0, 1, 2, 3], help="0 - nenhuma, 1 - uma, 2 - duas, 3 - tr√™s ou mais")
        
    col4, col5, col6 = st.columns(3)
    
    with col4:
        st.subheader("Suporte e Atividades")
        schoolsup = st.selectbox("Suporte educacional extra da escola", ["yes", "no"])
        famsup = st.selectbox("Suporte educacional familiar", ["yes", "no"])
        paid = st.selectbox("Aulas extras pagas", ["yes", "no"])
        activities = st.selectbox("Atividades extracurriculares", ["yes", "no"])
        nursery = st.selectbox("Frequentou jardim de inf√¢ncia", ["yes", "no"])
        
    with col5:
        st.subheader("Aspira√ß√µes e Relacionamentos")
        higher = st.selectbox("Deseja seguir ensino superior", ["yes", "no"])
        internet = st.selectbox("Acesso √† internet em casa", ["yes", "no"])
        romantic = st.selectbox("Em relacionamento rom√¢ntico", ["yes", "no"])
        famrel = st.selectbox("Qualidade das rela√ß√µes familiares", [1, 2, 3, 4, 5], help="1 - muito m√° a 5 - excelente")
        
    with col6:
        st.subheader("Lazer e Sa√∫de")
        freetime = st.selectbox("Tempo livre ap√≥s a escola", [1, 2, 3, 4, 5], help="1 - muito pouco a 5 - muito")
        goout = st.selectbox("Sair com amigos", [1, 2, 3, 4, 5], help="1 - muito pouco a 5 - muito")
        Dalc = st.selectbox("Consumo de √°lcool durante a semana", [1, 2, 3, 4, 5], help="1 - muito baixo a 5 - muito alto")
        Walc = st.selectbox("Consumo de √°lcool no fim de semana", [1, 2, 3, 4, 5], help="1 - muito baixo a 5 - muito alto")
        health = st.selectbox("Estado de sa√∫de atual", [1, 2, 3, 4, 5], help="1 - muito mau a 5 - muito bom")
        absences = st.number_input("N√∫mero de faltas", min_value=0, max_value=93, value=0)
    
    # Bot√£o para prever
    if st.button("Prever"):
        # Criar um dataframe com os dados do novo aluno
        new_student = pd.DataFrame({
            'school': [school],
            'sex': [sex],
            'age': [age],
            'address': [address],
            'famsize': [famsize],
            'Pstatus': [Pstatus],
            'Medu': [Medu],
            'Fedu': [Fedu],
            'Mjob': [Mjob],
            'Fjob': [Fjob],
            'reason': [reason],
            'guardian': [guardian],
            'traveltime': [traveltime],
            'studytime': [studytime],
            'failures': [failures],
            'schoolsup': [schoolsup],
            'famsup': [famsup],
            'paid': [paid],
            'activities': [activities],
            'nursery': [nursery],
            'higher': [higher],
            'internet': [internet],
            'romantic': [romantic],
            'famrel': [famrel],
            'freetime': [freetime],
            'goout': [goout],
            'Dalc': [Dalc],
            'Walc': [Walc],
            'health': [health],
            'absences': [absences]
        })
        
        # Aplicar as mesmas transforma√ß√µes que foram aplicadas ao dataset original
        new_student_processed = new_student.copy()
        new_student_processed['school'] = new_student_processed['school'].map({'GP': 1, 'MS': 0})
        new_student_processed['sex'] = new_student_processed['sex'].map({'F': 1, 'M': 0})
        new_student_processed['address'] = new_student_processed['address'].map({'R': 1, 'U': 0})
        new_student_processed['famsize'] = new_student_processed['famsize'].map({'GT3': 1, 'LE3': 0})
        new_student_processed['Pstatus'] = new_student_processed['Pstatus'].map({'T': 1, 'A': 0})
        new_student_processed['schoolsup'] = new_student_processed['schoolsup'].map({'yes': 1, 'no': 0})
        new_student_processed['famsup'] = new_student_processed['famsup'].map({'yes': 1, 'no': 0})
        new_student_processed['paid'] = new_student_processed['paid'].map({'yes': 1, 'no': 0})
        new_student_processed['activities'] = new_student_processed['activities'].map({'yes': 1, 'no': 0})
        new_student_processed['nursery'] = new_student_processed['nursery'].map({'yes': 1, 'no': 0})
        new_student_processed['higher'] = new_student_processed['higher'].map({'yes': 1, 'no': 0})
        new_student_processed['internet'] = new_student_processed['internet'].map({'yes': 1, 'no': 0})
        new_student_processed['romantic'] = new_student_processed['romantic'].map({'yes': 1, 'no': 0})
        
        # Aplicar one-hot encoding para vari√°veis categ√≥ricas
        # Mjob
        mjob_cols = ['Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher']
        for col in mjob_cols:
            new_student_processed[col] = 0
        if new_student['Mjob'].iloc[0] != 'at_home':  # at_home √© a categoria de refer√™ncia
            col_name = f"Mjob_{new_student['Mjob'].iloc[0]}"
            if col_name in mjob_cols:
                new_student_processed[col_name] = 1
        
        # Fjob
        fjob_cols = ['Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher']
        for col in fjob_cols:
            new_student_processed[col] = 0
        if new_student['Fjob'].iloc[0] != 'at_home':  # at_home √© a categoria de refer√™ncia
            col_name = f"Fjob_{new_student['Fjob'].iloc[0]}"
            if col_name in fjob_cols:
                new_student_processed[col_name] = 1
        
        # reason
        reason_cols = ['reason_home', 'reason_other', 'reason_reputation']
        for col in reason_cols:
            new_student_processed[col] = 0
        if new_student['reason'].iloc[0] != 'course':  # course √© a categoria de refer√™ncia
            col_name = f"reason_{new_student['reason'].iloc[0]}"
            if col_name in reason_cols:
                new_student_processed[col_name] = 1
        
        # guardian
        guardian_cols = ['guardian_mother', 'guardian_other']
        for col in guardian_cols:
            new_student_processed[col] = 0
        if new_student['guardian'].iloc[0] != 'father':  # father √© a categoria de refer√™ncia
            col_name = f"guardian_{new_student['guardian'].iloc[0]}"
            if col_name in guardian_cols:
                new_student_processed[col_name] = 1
        
        # Remover colunas categ√≥ricas originais
        new_student_processed = new_student_processed.drop(['Mjob', 'Fjob', 'reason', 'guardian'], axis=1)
        
        # Garantir que todas as colunas necess√°rias est√£o presentes
        for col in X.columns:
            if col not in new_student_processed.columns:
                new_student_processed[col] = 0
        
        # Reordenar colunas para corresponder ao dataset de treino
        new_student_processed = new_student_processed[X.columns]
        
        # Fazer previs√µes com todos os modelos
        predictions = {}
        probabilities = {}
        
        for name, model in models.items():
            prob = model.predict_proba(new_student_processed)[0][1]  # Probabilidade da classe positiva (passed=1)
            probabilities[name] = prob
            predictions[name] = 1 if prob >= 0.5 else 0  # Previs√£o bin√°ria de cada modelo
        
        # Contar quantos modelos aprovam o aluno
        approving_models = sum(predictions.values())
        total_models = len(models)
        
        # Decis√£o baseada na maioria dos modelos (mais de metade)
        ensemble_prediction = 1 if approving_models > total_models / 2 else 0
        
        # Exibir resultados
        st.markdown("---")
        st.subheader("Resultado da Previs√£o")
        
        # Mostrar resultado baseado na maioria dos modelos
        st.markdown(f"### Resultado Final")
        
        if ensemble_prediction == 1:
            st.success(f"O aluno tem alta probabilidade de ser **APROVADO**")
        else:
            st.error(f"O aluno tem alta probabilidade de ser **REPROVADO**")
        